#  VeritasLens: Media Forensic Dashboard

##  Project Overview

VeritasLens is a hands-on attempt to build a simple but powerful tool for **media forensics**. Specifically, checking if a news image and its caption are consistent, authentic, and not generated by AI.

In the age of deepfakes and viral misinformation, simply looking at an image isn't enough. VeritasLens brings together several state-of-the-art AI and forensic techniques into one dashboard to give a quick "fact-check" score.

## Tech Stack & Verification Components

VeritasLens is built on several core components, with each handling a different part of the verification process:

| Component | Verification Task | Key Models / Libraries |
| :--- | :--- | :--- |
| **Forensic Analysis** | Detects digital tampering and known media re-use. | **ELA (Error Level Analysis)** for tampering; **`imagehash` (pHash)** for duplicate detection.  |
| **AI Generation Check** | Determines the likelihood of the image being AI-generated (a deepfake). | `umm-maybe/AI-image-detector` (Hugging Face Model). |
| **Visual Q&A (VQA)** | Generates a description of the image and answers questions about its contents (e.g., "What is the location?"). | `Salesforce/blip2-opt-2.7b` (Vision-Language Model). |
| **Semantic Consistency** | Checks if the user's text caption matches the AI's visual description. | `cross-encoder/nli-distilroberta-base` (Natural Language Inference). |
| **Entity Extraction** | Pulls out key locations (GPE) and dates from the user's caption for cross-checking. | `spaCy` (`en_core_web_sm`). |

## The Dashboard Architecture

The project runs a full web application designed to be launched directly from a Colab notebook:

* **Backend:** **FastAPI** is used to create a lightweight, modern web API. It handles the image upload, runs the analysis logic (in the `NewsVerifier` class), and sends the results back as JSON.
* **Frontend:** A simple, single-page dashboard built with **HTML/CSS (Bootstrap)** and **JavaScript** to display the report clearly and handle the submission form.
* **Deployment:** **Uvicorn** runs the FastAPI server, and **`pyngrok`** creates a secure tunnel so the local server can be accessed via a public URL from the Colab notebook.

##  How to Run the Code

This project is designed to run easily in a Google Colab environment, leveraging its free GPU for the large models.

1.  **Upload the Notebook:** Upload the `Veritas_lens.ipynb` file to your Google Colab session.
2.  **Run Cells 1, 2, and 3:** These steps install dependencies, load the large AI models, and set up the FastAPI server/dashboard code.
3.  **Run Cell 4 (Start Server):**
    * This will initialize the `pyngrok` tunnel.
    * It will output a **Public URL**.
    * Click the link therein to open the live, interactive dashboard in a new tab.

---

**Note:** For running outside of Colab, refer to the `app.py` and `requirements.txt` files for local setup instructions.
